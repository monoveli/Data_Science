ğŸŒŸ Plano de Estudos para a Monica

ğŸ“‹ VisÃ£o Geral
Este plano de estudos foi desenvolvido para uma analista de dados que deseja migrar para a Ã¡rea de ciÃªncia de dados, com foco em aprendizado progressivo e estruturado. O objetivo Ã© construir uma base sÃ³lida em estatÃ­stica, programaÃ§Ã£o e aprendizado de mÃ¡quina, preparando para atuar com maior autonomia em projetos de modelagem preditiva, anÃ¡lise de dados e experimentaÃ§Ã£o.
ğŸ¯ Objetivos de Desenvolvimento
Construir uma base forte em estatÃ­stica, programaÃ§Ã£o (principalmente em Python) e fundamentos de machine learning
Compreender os principais tipos de modelos preditivos (classificaÃ§Ã£o, regressÃ£o, agrupamento, etc.) e suas aplicaÃ§Ãµes prÃ¡ticas
Aprender a utilizar ferramentas comuns no dia a dia da ciÃªncia de dados, como Jupyter, pandas, scikit-learn e bibliotecas de visualizaÃ§Ã£o
Desenvolver raciocÃ­nio analÃ­tico para resolver problemas reais com dados
Praticar a criaÃ§Ã£o de pipelines simples de machine learning, com supervisÃ£o
Evoluir gradualmente para ter mais autonomia em anÃ¡lises, modelagem e comunicaÃ§Ã£o de resultados

Pre-work: Fundamentos de Engenharia de Software
Software Engineering for Data Scientists
Udacity Data Science Nanodegree
TÃ³pico: Object-Oriented Programming 
Explore object-oriented programming (OOP), including classes, instances, magic methods, inheritance, and polymorphism. Utilize professional coding patterns for efficient Python software development.
TÃ³pico: Code Reproducibility
Use and create virtual environments, write Python packages, manage file paths in a way that enables cross-platform compatibility, and ensure code quality through testing and linting.
TÃ³pico: Object-Oriented Programming 
Explore object-oriented programming (OOP), including classes, instances, magic methods, inheritance, and polymorphism. Utilize professional coding patterns for efficient Python software development.




ğŸ§© MÃ³dulo 1: Fundamentos de Modelagem Preditiva
TÃ³pico 1: RegressÃ£o Linear (1 semana)
Objetivos:
Entender o conceito de regressÃ£o linear e suas aplicaÃ§Ãµes
Aprender a fazer uma regressÃ£o no scikit-learn
Interpretar coeficientes
Exemplo em Python:
	 Prever o preÃ§o de casas com base em Ã¡rea e nÃºmero de quartos
	 (usando pandas, matplotlib, scikit-learn)
Notebook com exemplo
RegressÃ£o Linear Simples:
Em uma regressÃ£o linear simples, a ideia Ã© comparar duas variÃ¡veis quantitativas entre si. NÃ³s dividimos as variÃ¡veis entre: 
VariÃ¡vel resposta, ou dependente, que Ã© a variÃ¡vel que vamos querer prever (o comum Ã© posicionar essa variÃ¡vel no eixo Y);
VariÃ¡vel explicativa, ou independente, que Ã© a variÃ¡vel que vamos utilizar para prever a variÃ¡vel dependente (o comum Ã© posicionar essa variÃ¡vel no eixo X).  
Uma vez que estamos lidando com duas variÃ¡veis quantitativas, um tipo de visualizaÃ§Ã£o comum e Ãºtil para comparÃ¡-las Ã© o Scatter Plot. 
Uma mÃ©trica que Ã© relacionada com o Scatter Plot e quantifica a relaÃ§Ã£o linearntre duas variÃ¡veis quantitativas - muito Ãºtil no nosso contexto de RegressÃ£o Linear - Ã© o Coeficiente de CorrelaÃ§Ã£o de Pearson.  A partir dele podemos mensurar a forÃ§a e a direÃ§Ã£o da nossa relaÃ§Ã£o.  

A ideia da regressÃ£o linear Ã© traÃ§ar uma reta que represente a relaÃ§Ã£o entre as duas variÃ¡veis que estamos trabalhando. Para definir uma reta, precisamos de um intercepto (intercept) e uma inclinaÃ§Ã£o (slope).
Intercept (b_0) - O valor predito para a resposta quando a variÃ¡vel dependente (X) Ã© zero
Slope (b_1) - A mudanÃ§a prevista na resposta para cada unidade aumentada na variÃ¡vel dependente (X)

When is it ok to remove the intercept in a linear regression model?
E como encontrar a linha que melhor define a relaÃ§Ã£o entre duas variÃ¡veis?
O mÃ©todo mais comum Ã© chamado de least-squares, que encontra a reta que minimiza 

Ou seja, minimiza a soma do quadrado das diferenÃ§as entre as distÃ¢ncias da linha atÃ© os pontos. RepresentaÃ§Ã£o visual: 


Como interpretar e avaliar uma regressÃ£o linear? 
R-squared: Ã© o quadrado do coeficiente de correlaÃ§Ã£o de Pearson. Normalmente definimos o R-squared como a quantidade de variabilidade da variÃ¡vel resposta que Ã© explicada pela variÃ¡vel dependente no nosso modelo. 
DiscussÃ£o sobre R-squared: casos em que a mÃ©trica nÃ£o Ã© tÃ£o Ãºtil
RegressÃ£o Linear MÃºltipla 
Na regressÃ£o linear mÃºltipla, utilizamos mais de uma variÃ¡vel (podendo ser tanto quantitativas quanto categÃ³ricas) para prever a variÃ¡vel resposta.

Nesse caso, como vamos trabalhar com ambas variÃ¡veis categÃ³ricas e quantitativas, precisamos lembrar que o coeficiente de correlaÃ§Ã£o apenas mede a relaÃ§Ã£o entre duas variÃ¡veis quantitativas. 
Podemos interpretar os coeficientes na regressÃ£o linear mÃºltipla como o aumento ou diminuiÃ§Ã£o previsto na variÃ¡vel resposta para cada aumento de uma unidade na variÃ¡vel explicativa, mantendo todas as outras variÃ¡veis no modelo constantes.
Lembrete: O intercepto tambÃ©m Ã© um coeficiente!
Para adicionar variÃ¡veis categÃ³ricas no nosso modelo, precisamos transformar elas em dummy variables. O jeito mais comum de realizar isso Ã© um mÃ©todo de 0, 1 encoding, em que Ã© criada uma coluna para cada valor possÃ­vel distinto da coluna categÃ³rica menos um - jÃ¡ que o Ãºltimo valor pode ser inferido das outras colunas (baseline). EntÃ£o, utiliza-se 0 ou 1 para indicar se aquele valor estÃ¡ presente ou nÃ£o.  


Ã‰ equivalente ao one hot encoding? 
TÃ³pico 2: Pressupostos EstatÃ­sticos da RegressÃ£o 
Objetivos:
Verificar linearidade, normalidade dos resÃ­duos, homocedasticidade, independÃªncia
Diagnosticar problemas nos modelos
Exemplo em Python:
	 Fazer grÃ¡ficos de resÃ­duos e histograma dos erros da regressÃ£o do topico1
	 (usar seaborn, statsmodels, scipy)
Pressupostos da RegressÃ£o Linear:
1. Linearidade
Os dados devem ter uma relaÃ§Ã£o linear entre variÃ¡veis preditoras e resposta.
Como verificar? GrÃ¡fico de resÃ­duos vs valores previstos (deve mostrar padrÃ£o aleatÃ³rio)
2. Homocedasticidade (VariÃ¢ncia Constante)
A variÃ¢ncia dos resÃ­duos deve ser constante ao longo de todos os valores previstos
Como verificar? TambÃ©m pode ser verificado pelo grÃ¡fico de |resÃ­duos| vs valores previstos ou Teste de hipÃ³teses, por exemplo Teste de Levene
Link explicaÃ§Ã£o teste de Levene



3. Normalidade dos ResÃ­duos
Os resÃ­duos devem seguir distribuiÃ§Ã£o normal
Como verificar? Histograma dos resÃ­duos, Q-Q plot, Teste de Shapiro-Wilk
Link para testes para verificaÃ§Ã£o de normalidade


4. IndependÃªncia dos Erros
Os resÃ­duos devem ser independentes entre si -> Dados temporais ou espaciais podem violar este pressuposto
5. AusÃªncia de Multicolinearidade
VariÃ¡veis preditoras nÃ£o devem estar muito correlacionadas
Como verificar? Matriz de correlaÃ§Ã£o, VIF (Variance Inflation Factor)
6. Outliers
Pontos que se afastam muito da tendÃªncia podem distorcer o modelo
VerificaÃ§Ã£o: Boxplots, resÃ­duos padronizados (|z| > 3)

TÃ³pico 3: RegressÃ£o LogÃ­stica
Objetivos:
ClassificaÃ§Ã£o binÃ¡ria
IntuiÃ§Ã£o do logit e interpretaÃ§Ã£o de outputs
Exemplo em Python:
	Prever se um cliente vai ou nÃ£o clicar em uma campanha de marketing
	(usando pandas, scikit-learn, confusion_matrix)
A regressÃ£o logÃ­stica Ã© utilizada quando queremos prever uma variÃ¡vel categÃ³rica binÃ¡ria (quando sÃ³ temos dois possÃ­veis resultados, geralmente associados a um â€œsucessoâ€ e um â€œfracasso". 
Na regressÃ£o linear, vimos que a variÃ¡vel resposta pode assumir qualquer valor sem restriÃ§Ã£o - mesmo valores que nÃ£o fazem sentido. Na regressÃ£o logÃ­stica a variÃ¡vel resposta Ã© limitada a uma probabilidade entre 0 e 1.

Para fazer uma regressÃ£o logÃ­stica, precisamos:
Atribuir valores de 0 e 1 para a coluna categÃ³rica binÃ¡ria que iremos usar como variÃ¡vel resposta. Por exemplo, para o exemplo que vamos trabalhar de entender se um cliente clicou ou nÃ£o em uma campanha de marketing, o clique pode ser atribuÃ­do ao 1 (o â€œsucessoâ€) e o nÃ£o-clique ao 0. 
Um modelo linear vai prever o logaritmo da razÃ£o de chances, em que:
RazÃ£o de chances: a probabilidade de um evento ocorrer sob a probabilidade dele nÃ£o ocorrer
Logaritmo: Controla a razÃ£o de chances para ser um nÃºmero entre 0 e 1
Com algumas transformaÃ§Ãµes matemÃ¡ticas, a funÃ§Ã£o passa a ter essa cara: 

que resolve a probabilidade diretamente! Essa funÃ§Ã£o Ã© chamada SigmÃ³ide.
A funÃ§Ã£o SigmÃ³ide Ã© responsÃ¡vel por pegar um valor de uma linha de regressÃ£o linear e mapear entre 0 e 1.



Cada Î²i representa a mudanÃ§a no log-odds de p quando a variÃ¡vel  aumenta em 1 unidade, mantendo as outras fixas.
Log-odds nÃ£o Ã© intuitivo â†’ por isso a gente converte para odds ratio.
Se OR>1 â†’  aumenta as chances do evento acontecer (ex.: maior chance de compra).
OR<1 â†’  diminui as chances.
OR=1 â†’â€‹ nÃ£o afeta a probabilidade.








Para avaliar um modelo de regressÃ£o logÃ­stica, a avaliaÃ§Ã£o mais comum Ã© a acurÃ¡cia, que mede a proporÃ§Ã£o de acertos. PorÃ©m, a acurÃ¡cia nem sempre Ã© a melhor medida, principalmente em datasets muito desbalanceados. 
Matrizes de confusÃ£o: 

Recall: Positivo Verdadeiro (Pos,Pos) / (Positivo Verdadeiro (Pos,Pos) + Falso Negativo (Pos,Neg). Ou seja, de todos os itens positivos de verdade, quantos foram corretamente classificados como positivos. 
Precision: (Pos,Pos) / (Positivo Verdadeiro (Pos,Pos) + Falso Positivo (Neg,Pos)). Ou seja, de todos os itens preditos como positivos, quantos realmente sÃ£o positivos. 
Material sobre curva ROC e AUC
Curva ROC
A curva ROC Ã© uma representaÃ§Ã£o visual da performance do modelo em todos os limites. Ela Ã© desenhada calculando a taxa de verdadeiros positivos (TPR, na sigla em inglÃªs) e a taxa de falsos positivos (FPR, na sigla em inglÃªs) em todos os limites possÃ­veis (na prÃ¡tica, em intervalos selecionados) e, em seguida, representando a TPR em relaÃ§Ã£o Ã  FPR. Um modelo perfeito, que em algum limite tem um TPR de 1,0 e um FPR de 0,0, pode ser representado por um ponto em (0, 1) se todos os outros limites forem ignorados ou pelo seguinte:

Ãrea sob a curva (AUC)
A Ã¡rea sob a curva ROC (AUC) representa a probabilidade de o modelo, se receber um exemplo positivo e negativo escolhido aleatoriamente, classificar o positivo como melhor do que o negativo.
A AUC Ã© uma medida Ãºtil para comparar a performance de dois modelos diferentes, desde que o conjunto de dados esteja aproximadamente equilibrado. O modelo com maior Ã¡rea sob a curva geralmente Ã© o melhor.


Material muito bom sobre curva ROC, AUC e Reg Log
TÃ³pico Extra: PadronizaÃ§Ã£o/NormalizaÃ§Ã£o dos Dados

Material de apoio - Artigo no Medium sobre padronizaÃ§Ã£o
Material de apoio - Google Developers sobre normalizaÃ§Ã£o
Objetivos:
Entender a importÃ¢ncia do dimensionamento de dados em Machine Learning
Conhecer diferentes mÃ©todos de padronizaÃ§Ã£o e normalizaÃ§Ã£o
Saber quando aplicar cada tÃ©cnica
Por que Padronizar/Normalizar?
Problema com dados nÃ£o dimensionados:
Algoritmos baseados em gradiente podem ter convergÃªncia lenta ou nÃ£o convergir
Modelo pode dar peso excessivo a features com escalas maiores
Risco de valores NaN quando features tÃªm valores muito altos
Performance preditiva degradada
Decision Trees e Random Forest sÃ£o robustos e nÃ£o necessitam dimensionamento* -> ver com mais profundidade nos mÃ³dulos das Ã¡rvores
PadronizaÃ§Ã£o
Resulta em mÃ©dia = 0 e desvio padrÃ£o = 1 e mantÃ©m a forma da distribuiÃ§Ã£o original
NormalizaÃ§Ã£o:
Coloca variÃ¡veis no intervalo [0,1] ou [-1,1] se houver valores negativos -> comprime todos os valores dentro de um intervalo especÃ­fico
MÃ©todos de PadronizaÃ§Ã£o:
StandardScaler

Quando usar: Dados com distribuiÃ§Ã£o aproximadamente normal, algoritmos como regressÃ£o linear e logÃ­stica, quando nÃ£o temos outliers extremos
MinMaxScaler

Quando usar: DistribuiÃ§Ã£o nÃ£o Ã© normal, desvio padrÃ£o pequeno, quando queremos preservar a distribuiÃ§Ã£o original
NÃ£o trata outliers efetivamente
RobustScaler

Quando usar: PresenÃ§a de outliers (baseado em percentis, nÃ£o em mÃ©dia/desvio padrÃ£o ou seja reduz impacto negativo dos outliers)
MÃ©todos de NormalizaÃ§Ã£o:
Escalonamento Linear (Linear Scaling)
Converte valores para intervalo padrÃ£o [0,1] ou [-1,+1]
Quando usar: Limites dos dados sÃ£o estÃ¡veis ao longo do tempo, poucos outliers nÃ£o extremos, distribuiÃ§Ã£o aproximadamente uniforme
Exemplo: idade humana (0-100 anos)
Escalonamento Z-Score
Mesmo que StandardScaler - mais comum que escalonamento linear
 Escalonamento LogarÃ­tmico
Para dados com distribuiÃ§Ã£o muito assimÃ©trica
Regra Geral de Escolha:
SituaÃ§Ã£o
MÃ©todo Recomendado
DistribuiÃ§Ã£o normal, sem outliers
StandardScaler
DistribuiÃ§Ã£o nÃ£o-normal
MinMaxScaler
PresenÃ§a de outliers
RobustScaler
Dados com muita disparidade de escalas
NormalizaÃ§Ã£o obrigatÃ³ria


Importante lembrar: Se normalizar no treino, precisa normalizar na prediÃ§Ã£o tambÃ©m.

TÃ³pico 4: AvaliaÃ§Ã£o de Modelos + RegularizaÃ§Ã£o
Objetivos:
RÂ², MAE, MAPE, RMSE (para regressÃ£o)
IntroduÃ§Ã£o a overfitting e regularizaÃ§Ã£o (Ridge, Lasso, ElasticNet)
Exemplo em Python:
	Comparar os resultados de uma regressÃ£o linear simples com Ridge e Lasso
(usar sklearn.linear_model)

Overfitting
Acontece quando um modelo aprende os dados de treinamento tÃ£o bem, que confunde ruÃ­do/especificidades dos dados de treino como padrÃµes. Isso leva a uma performance ruim para dados que nÃ£o sejam de treino.
Em termos mais tÃ©cnicos, significa que o modelo nÃ£o Ã© generalista.
Como isso aparece? Como detectar overfitting?
Quando a mÃ©trica escolhida para avaliaÃ§Ã£o possuÃ­ resultados muito bons para os dados de treino e para os dados de teste, resultados bem piores.
Quando notamos introduÃ§Ã£o de ruÃ­do excessivo nos dados de previsÃ£o.
Exemplo prÃ¡tico de caso de Overfitting dentro do contexto de SR:
Quando utilizÃ¡vamos o modelo Prophet para prever pedidos, como nÃ£o especificamos tanto a sazonalidade, ele comeÃ§ou a aprender os ruÃ­dos e variaÃ§Ãµes pequenas como sazonalidades! O resultado era uma previsÃ£o sem sazonalidade clara e muita introduÃ§Ã£o de ruÃ­do, mesmo quando os dados de input eram estÃ¡veis.
â€”
RegularizaÃ§Ã£o: artigo no MÃ©dium sobre
RegularizaÃ§Ã£o Ã© o processo de adicionar informaÃ§Ãµes para prevenir over-fitting.
LASSO(Least Absolute Shrinkable and Selection Operator) - L1 Regularization:
Adicionamos uma â€œPenalidadeâ€ na funÃ§Ã£o objetivo baseado nos valores absolutos dos coeficientes.
O termos de regularizaÃ§Ã£o L1 Ã© a soma dos valores absolutos dos coeficientes multiplicado por um parÃ¢metro Î».
 Se Î» Ã© grande pode suprimir os coeficientes de features importantes (alta correlaÃ§Ã£o).
Se Î» Ã© 0, a loss vira RSS. 
O tamanho de Î» define se queremos evitar under-fitting (quando Î» Ã© grande) ou over-fitting (quando Î» Ã© pequeno).

Na prÃ¡tica, o efeito Ã©: se temos uma linha passando por todos os pontos de dados, a soma quadrÃ¡tica dos erros vai ser 0 (primeira parte da funÃ§Ã£o). O termo adicional que colocamos (segunda parte da funÃ§Ã£o) deve ser minimizado para minimizar a funÃ§Ã£o de custo. Mas, fazendo isso, faremos a linha nÃ£o passar exatamente por todos os pontos, e isso previne overfitting. 
RIDGE Regularizarion - L2 Regularization:
Ã‰ uma variaÃ§Ã£o do LASSO, em que o termo de penalizaÃ§Ã£o nÃ£o pode ser zerado jÃ¡ que elevamos o coeficiente ao quadrado.

â€”
Elastic-Net Regression
Ã‰ um mix entre LASSO e Ridge, que adiciona os dois termos (L1 e L2).
Por que misturar?
 L1 forÃ§a alguns coeficientes a virar exatamente zero (feature selection).
L2 encolhe todos os coeficientes proporcionalmente (lida bem com multicolinearidade).
Elastic-Net traz o melhor dos dois: faz seleÃ§Ã£o de variÃ¡veis e mantÃ©m estabilidade quando hÃ¡ correlaÃ§Ã£o alta entre features.
â€”
Quando usar cada um? 
Se vocÃª nÃ£o realizou feature selection nos seus dados, e tem vÃ¡rias features com alta correlaÃ§Ã£o e precisa tirar algumas que nÃ£o sÃ£o necessÃ¡rias, LASSO Ã© uma melhor opÃ§Ã£o. 
Se o nÃºmero de features Ã© maior que o nÃºmero de observaÃ§Ãµes e temos multicolinearidade, RIDGE Ã© uma melhor opÃ§Ã£o.
Se temos os dois casos, usar o Elastic-Net.
â€”
Resumo das mÃ©tricas de avaliaÃ§Ã£o

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
MÃ³dulo Extra: Gradiente Descendente 
Objetivos:
Entender como os algoritmos "aprendem" minimizando erros
Visualizar o conceito de descida em uma funÃ§Ã£o de custo
Compreender learning rate
Exemplo em Python:
Implementar gradiente descendente simples para regressÃ£o linear (usando numpy, matplotlib para visualizar a descida)
Material - MÃ©dium
Notebook
O gradiente descendente Ã© o algoritmo que permite que os modelos de machine learning "aprendam". Ã‰ o processo matemÃ¡tico por trÃ¡s de praticamente todos os algoritmos ( regressÃ£o linear, regressÃ£o logÃ­stica, redes neurais, etc.)
A ideia dele Ã© que, uma vez que temos uma funÃ§Ã£o de custo (que mede o quanto errado seu modelo ta) e quer encontrar os parÃ¢metros que minimizam essa funÃ§Ã£o. O gradiente descendente Ã© o mÃ©todo para chegar nesse ponto de erro mÃ­nimo.

Como funciona?
Fazemos o primeiro chute de valores aleatÃ³rios para os parÃ¢metros do modelo
Calculamos o erro atual do modelo usando a funÃ§Ã£o de custo
Calculamos a derivada da funÃ§Ã£o de custo (o gradiente) 
Interpretamos a derivada para entender em em qual direÃ§Ã£o devemos ajustar os parÃ¢metros para reduzir o erro
Atualizamos os parÃ¢metros na direÃ§Ã£o que reduz o erro
Repetimos atÃ© convergir (atÃ© o erro parar de diminuir significativamente)

Learning Rate
O learning rate controla o tamanho dos passos que vamos dar para ajustar os parÃ¢metros:
Learning rate muito alto: pode fazer o algoritmo pular o ponto Ã³timo e nunca convergir. O erro vai ficar oscilando ou atÃ© aumentando.
Learning rate muito baixo: vai convergir muito devagar. Pode levar muito tempo para treinar.



FunÃ§Ãµes de custo/loss function
Ã‰ sempre escolhido a mesma da mÃ©trica de avaliaÃ§Ã£o do modelo? Como escolher uma loss boa? 

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

MÃ³dulo Extra: Feature Selection 
Objetivos:
Identificar features mais relevantes para o modelo
Reduzir dimensionalidade dos dados
Melhorar performance e interpretabilidade
Exemplo em Python:
Selecionar as 5 melhores features de um dataset de marketing usando pelo menos um mÃ©todo univariado e dois mÃ©todos multivariados (que consideram interaÃ§Ãµes entre features na seleÃ§Ã£o), e pro mesmo dataset aplicar PCA. Comparar os resultados.

Feature Selection Ã© onde identificamos e selecionamos as variÃ¡veis mais relevantes para o modelo. A ideia Ã© manter apenas as features que contribuem significativamente para a performance, e tirar variÃ¡veis redundantes, irrelevantes ou que vÃ£o introduzir ruÃ­do.
Ajuda em:
ReduÃ§Ã£o de overfitting: menos variÃ¡veis diminuem a complexidade do modelo
Melhoria na interpretabilidade: modelos com menos features sÃ£o mais fÃ¡ceis de explicar
ReduÃ§Ã£o do tempo de treinamento: menos dados para processar
ReduÃ§Ã£o de ruÃ­do: eliminaÃ§Ã£o de variÃ¡veis que nÃ£o agregam valor preditivo
MÃ©todos Univariados
Avaliam cada feature individualmente em relaÃ§Ã£o ao target, sem considerar interaÃ§Ãµes entre features. Geralmente sÃ£o mais rÃ¡pidos de calcular, simples de interpretar e bons mÃ©todos baselines, mas ignoram interaÃ§Ãµes entre features e podem descartar features importantes que sÃ³ funcionam em combinaÃ§Ã£o
Exemplos comuns:
SelectKBest: seleciona K melhores features baseado em teste estatÃ­stico
Chi-squared: para features categÃ³ricas e target categÃ³rico
F-test (ANOVA): para features numÃ©ricas e target categÃ³rico
MÃ©todos Multivariados
Consideram interaÃ§Ãµes entre features durante a seleÃ§Ã£o.
Wrapper Methods
Usam o prÃ³prio modelo para avaliar subconjuntos de features. 
Recursive Feature Elimination (RFE):
Treina modelo com todas as features
Remove features menos importantes iterativamente
Repete atÃ© atingir nÃºmero desejado de features
Forward/Backward Selection:
Forward: adiciona features uma por vez
Backward: remove features uma por vez
Embedded Methods
SeleÃ§Ã£o de features integrada ao processo de treinamento do modelo. Ã‰ o caso das RegularizaÃ§Ãµes que vimos anteriormente. 
Feature Importance (Tree-based models): Random Forest, XGBoost fornecem importÃ¢ncia das features
ReduÃ§Ã£o de Dimensionalidade vs Feature Selection
Feature Selection: MantÃ©m features originais (interpretabilidade preservada), seleciona subconjunto das variÃ¡veis existentes, features selecionadas tÃªm significado original
ReduÃ§Ã£o de Dimensionalidade (ex: PCA): Cria novas features como combinaÃ§Ãµes das originais, reduz dimensÃµes atravÃ©s de transformaÃ§Ãµes matemÃ¡ticas, features resultantes podem perder interpretabilidade original
Principal Component Analysis (PCA)
Como Funciona:
Padroniza as variÃ¡veis (mÃ©dia 0, desvio padrÃ£o 1)
Calcula matriz de covariÃ¢ncia
Encontra autovalores e autovetores
Ordena componentes por variÃ¢ncia explicada
Seleciona primeiros N componentes
Detalhes sobre o cÃ¡lculo
CaracterÃ­sticas:
Componentes sÃ£o ortogonais: nÃ£o correlacionados entre si
Ordenados por variÃ¢ncia: primeiro componente explica mais variÃ¢ncia
CombinaÃ§Ã£o linear: cada componente Ã© soma ponderada das features originais
PreservaÃ§Ã£o de variÃ¢ncia: componentes mantÃªm mÃ¡xima variÃ¢ncia possÃ­vel
Quando Usar PCA: Quando temos features altamente correlacionadas, muitas features numÃ©ricas, necessidade de reduzir dimensionalidade mantendo informaÃ§Ã£o



Modelo
Default Loss
ObservaÃ§Ãµes sobre Learning Rate
RegressÃ£o Linear (sklearn)
MSE (Mean Squared Error)
scikit-learn usa otimizaÃ§Ã£o direta (nÃ£o gradiente) por padrÃ£o. Se usar SGDRegressor, a learning rate influencia a velocidade de convergÃªncia.
RegressÃ£o LogÃ­stica (sklearn)
Log Loss / Cross-Entropy
Otimiza via liblinear ou lbfgs por padrÃ£o; learning rate sÃ³ se usar SGDClassifier.
Random Forest / XGBoost / LightGBM / CatBoost
NÃ£o usa loss â€œtradicionalâ€ no scikit-learn; internamente usam critÃ©rios como Gini, MSE ou Log Loss
Learning rate existe em boosting (learning_rate) e controla o passo de cada Ã¡rvore na soma ponderada.
Redes Neurais (PyTorch / TensorFlow)
Nenhuma por padrÃ£o; vocÃª passa explÃ­cito (nn.MSELoss, nn.CrossEntropyLoss)
Learning rate define o tamanho do passo do gradiente; muito grande â†’ instÃ¡vel, muito pequeno â†’ lento.
ClassificaÃ§Ã£o BinÃ¡ria (PyTorch)
nn.BCEWithLogitsLoss ou nn.BCELoss
Mesma lÃ³gica: learning rate nÃ£o muda a funÃ§Ã£o, sÃ³ a velocidade de aprendizado.
ClassificaÃ§Ã£o Multiclasse (PyTorch)
nn.CrossEntropyLoss
Learning rate afeta convergÃªncia; se muito alta pode explodir gradientes.

1ï¸âƒ£ Qual Ã© a loss function default?
RegressÃ£o Linear (scikit-learn, PyTorch, TensorFlow) â†’ default normalmente Ã© Mean Squared Error (MSE).
RegressÃ£o LogÃ­stica / ClassificaÃ§Ã£o BinÃ¡ria â†’ default normalmente Ã© Binary Cross-Entropy (Log Loss).
ClassificaÃ§Ã£o Multiclasse â†’ default normalmente Ã© Categorical Cross-Entropy.
Redes neurais genÃ©ricas â†’ depende da camada de saÃ­da e do framework; por exemplo, nn.Linear sozinho nÃ£o define loss, vocÃª passa explicitamente.
ğŸ’¡ Resumo: cada modelo jÃ¡ â€œassumeâ€ uma loss que faz sentido para o tipo de problema (regressÃ£o ou classificaÃ§Ã£o).
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

ğŸŒ³  MÃ³dulo 2: Modelos com Ãrvores e Ensemble
TÃ³pico 1: Ãrvores de DecisÃ£o
Objetivos:
LÃ³gica de divisÃ£o dos dados
Vantagens e limitaÃ§Ãµes
Exemplo em Python:
	 Construir uma Ã¡rvore para classificar tipo de cliente com base em idade e renda
	(DecisionTreeClassifier, plot_tree)
TÃ³pico 2: Random Forest
Objetivos:
Combinar vÃ¡rias Ã¡rvores para melhorar performance
Feature importance
Exemplo em Python:
	 Prever churn com Random Forest e plotar a importÃ¢ncia das variÃ¡veis
	(RandomForestClassifier)
TÃ³pico 3 â€“ XGBoost (Extra: LightGBM, CatBoost)
Objetivos:
IntroduÃ§Ã£o a modelos gradient boosting
Ajuste de hiperparÃ¢metros bÃ¡sicos
Exemplo em Python:
	 Usar xgboost para prever se um cliente vai comprar ou nÃ£o
	(com avaliaÃ§Ã£o AUC, curva ROC)
TÃ³pico 4 â€“ Interpretabilidade de Ãrvores
Objetivos:
Feature importance, SHAP values
Explicar modelos para o negÃ³cio
Exemplo em Python:
	 Usar SHAP para mostrar o impacto das variÃ¡veis no modelo do topico anterior
	(shap.TreeExplainer)
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
ğŸš€ MÃ³dulo 3: Pipeline, Deploy e Boas PrÃ¡ticas 
TÃ³pico 1: Pipelines de Machine Learning e PrÃ©-processamento
Objetivos:
Compreender o ciclo completo de um pipeline com scikit-learn
Aplicar boas prÃ¡ticas de prÃ©-processamento: imputaÃ§Ã£o, escalonamento, encoding
Evitar problemas comuns como data leakage
Modularizar o cÃ³digo e tornar reproduzÃ­vel
Conceitos-chave:
Pipeline, ColumnTransformer, SimpleImputer, StandardScaler, OneHotEncoder
SeparaÃ§Ã£o entre treino e teste antes do prÃ©-processamento
FunÃ§Ãµes reutilizÃ¡veis (def preprocessar_dados(), def treinar_modelo())


Exemplo em Python:
 Criar um pipeline completo que:
Carrega os dados de clientes
Trata valores nulos e codifica variÃ¡veis categÃ³ricas
Treina um modelo de churn prediction
Avalia com mÃ©tricas como ROC AUC e precisÃ£o
TÃ³pico 2: Fundamentos de ProduÃ§Ã£o: Docker, Cloud e CI/CD
Objetivos:
Entender o que Ã© necessÃ¡rio para colocar um modelo no ar
Aprender o bÃ¡sico de Docker para empacotar cÃ³digo
Conhecer o ciclo CI/CD (ex: GitHub Actions)
Ter noÃ§Ãµes iniciais de uso da nuvem para cientistas de dados (S3, notebooks gerenciados, endpoints)
Exemplo em Python:
Exemplo prÃ¡tico sugerido:
Criar um requirements.txt
Versionar um projeto simples com GitHub
Criar um Dockerfile bÃ¡sico com Python e scikit-learn
Rodar o container localmente
Ativar um fluxo automÃ¡tico com GitHub Actions (por exemplo: rodar testes)
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
ğŸ§  MÃ³dulo 4: Aprendizado NÃ£o Supervisionado (Clustering)
Objetivos:
Entender os principais mÃ©todos de agrupamento (ex: K-means)
Aplicar clustering para segmentaÃ§Ã£o de dados sem rÃ³tulos
Avaliar qualidade do agrupamento com mÃ©tricas simples (ex: Ã­ndice de silhueta)
Exemplo em Python:
	Usar KMeans do scikit-learn para segmentar clientes com base em variÃ¡veis numÃ©ricas
Visualizar clusters com matplotlib ou seaborn
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
ğŸ¤– MÃ³dulo 5: IntroduÃ§Ã£o a Redes Neurais e Machine Learning / IA

Objetivos:
Entender o que sÃ£o redes neurais e por que sÃ£o importantes no contexto de Machine Learning e InteligÃªncia Artificial
Conhecer a estrutura bÃ¡sica de uma rede neural: camadas, neurÃ´nios, ativaÃ§Ã£o
Compreender conceitos simples como forward propagation, funÃ§Ã£o de perda e backpropagation (intuitivamente)
Aprender a criar um modelo de rede neural simples usando bibliotecas como Keras/TensorFlow ou PyTorch
Comparar redes neurais bÃ¡sicas com modelos tradicionais como regressÃ£o e Ã¡rvores
ConteÃºdo:
O que Ã© uma rede neural: inspiraÃ§Ã£o biolÃ³gica e aplicaÃ§Ã£o computacional
Camadas: entrada, escondidas, saÃ­da
FunÃ§Ãµes de ativaÃ§Ã£o comuns: ReLU, Sigmoid, Softmax
Treinamento bÃ¡sico: como a rede â€œaprendeâ€ ajustando pesos
Exemplos de aplicaÃ§Ã£o: reconhecimento de imagem, classificaÃ§Ã£o de texto, sÃ©ries temporais
Exemplo em Python:
Construir uma rede neural simples para classificaÃ§Ã£o binÃ¡ria usando Keras
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
ğŸ” MÃ³dulos extras (opcionais, para revisÃ£o rÃ¡pida)
Extra 1: AnÃ¡lise ExploratÃ³ria e Storytelling com Dados
Recapitular boas prÃ¡ticas de visualizaÃ§Ã£o e interpretaÃ§Ã£o
TÃ©cnicas rÃ¡pidas para comunicaÃ§Ã£o clara de insights


Extra 2: Testes de HipÃ³teses e AB Testing
Revisar conceitos de testes estatÃ­sticos bÃ¡sicos (t-test, p-valor
Entender o ciclo de um teste A/B simples


ğŸš€  MÃ³dulo Carreira
O que do que vocÃª anotou atÃ© agora acha que jÃ¡ domina de verdade?
Tenho comeÃ§ado a dominar as situaÃ§Ãµes em quando eu deveria/poderia utilizar uma regressÃ£o, como interpretar os resultados, quando pode ser Ãºtil mesmo sem ser no contexto preditivo - por exemplo, essa semana precisei mesurar qual era a diferenÃ§a mÃ©dia entre conversÃµes entre variantes com custos diferentes. Como alguns desses dados estavam bem esparsos somente tirar a diferenÃ§a entre pares adjacentes nÃ£o estava gerando uma resposta legal, entÃ£o fitei uma regressÃ£o e usei o coeficiente, multiplicado pela diferenÃ§a mÃ©dia entre custos, pra me dar essa diferenÃ§a mÃ©dia! Os resultados fizeram bem mais sentido, e tambÃ©m consegui correlacionar o R2 pra interpretaÃ§Ã£o. A matemÃ¡tica por trÃ¡s da coisa tambÃ©m tem feito bem mais sentido.
O que vocÃª sente que ainda nÃ£o conseguiu transformar em prÃ¡tica, sÃ³ estÃ¡ no papel?
Ainda nÃ£o consegui transformar em prÃ¡tica talvez a parte de transformaÃ§Ãµes - tanto normalizaÃ§Ã£o quando regularizaÃ§Ãµes, por mais que tenha conseguido aplicar o cÃ³digo e entendido a teoria, acho que ajudaria muito um exemplo por exemplo, pra regularizaÃ§Ã£o, em que eu tenho um overfitting para resolver, por que nos estudos que fiz acabou nÃ£o tendo diferenÃ§a significativa entre os resultados usando as tÃ©cnicas.
Se tivesse que explicar em 5 minutos o que estudou essa semana para alguÃ©m da Ã¡rea de negÃ³cio, como faria?
	â€œ Essa semana, estudei sobre maneiras de resolver quando temos um problema de falta de adaptaÃ§Ã£o dos dados. Por exemplo, se estamos querendo prever pedidos e utilizamos dados da Ã©poca de Big Brother, o modelo pode aprender alguns padrÃµes relativos Ã s variaÃ§Ãµes pelo BBB - por exemplo, alta de pedidos na prova do anjo. O problema Ã© que nÃ£o temos BBB o ano todo e queremos uma soluÃ§Ã£o que vai funcionar independente dessas especificidades da Ã©poca, ou seja, que o modelo aprenda o comportamento geral da coisa, que Ã© constante o ano todo (por exemplo: alta de pedidos no final do semana) do que comportamento especÃ­ficos do perÃ­odo que estamos dando para o modelo aprender. Pra isso, temos algumas soluÃ§Ãµes matemÃ¡ticas que nos ajudam com esse problema, desajustando o modelo de propÃ³sito em alguns pontos que sejam muitos especÃ­ficos e fora do padrÃ£o geral!â€
Qual diferenÃ§a prÃ¡tica vocÃª enxerga entre o que um Analista de Dados faz e o que um Cientista de Dados faz com o mesmo conjunto de dados?
Acho que varia como cada um tem que entender o problema. Enquanto um Analista de Dados tem que se aprofundar muito na parte de diagnÃ³stico, de entender o que aconteceu e o que pode ter impactado para os resultados, o Cientista de Dados tem que fazer isso de forma mais â€œprofundaâ€- nÃ£o necessariamente tal nuance vai acarretar em um problema para o modelo, mas o cientista de dados tem que se antecipar e jÃ¡ se preparar para isso.
Se tivesse que priorizar o prÃ³ximo tema de estudo com base no que vocÃª jÃ¡ sabe, qual escolheria e por quÃª?
Antes de entrar em modelos de Ãrvore, eu escolheria priorizar estudar a parte de Gradiente Descendente, que vejo que Ã© um tÃ³pico em comum entre vÃ¡rios assuntos de CiÃªncia de Dados, e a parte de diferentes features selection - que entram junto com as tÃ©cnicas de preparar os dados para os modelos. 
VocÃª sente que seu caderno estÃ¡ mais como um resumo teÃ³rico ou um guia de prÃ¡tica?
Mais como um resumo teÃ³rico e um compilado de referÃªncias Ãºteis, mas pra mim Ã© o que mais me ajuda a aprender e fixar os conceitos. Ã€s vezes o exercÃ­cio de ter que escrever as coisas de um jeito diferente jÃ¡ ajuda a pegar se eu realmente entendi o que foi passado ou nÃ£o.
Como podemos transformar suas anotaÃ§Ãµes em algo que vire portfÃ³lio (GitHub, Kaggle, Medium)?
Podemos criar um Gitlab com tanto Ã s anotaÃ§Ãµes quando os notebooks prÃ¡ticos!
De 0 a 10, qual sua confianÃ§a no que estudou essa semana? O que faria subir esse nÃºmero?
7 - acho que entra no mesmo ponto de â€œcomo eu conseguiria forÃ§ar um overfitting para conseguir agir na resoluÃ§Ã£o desse problema?â€

